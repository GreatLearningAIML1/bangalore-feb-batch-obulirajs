{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGIsF1ADyJ58"
   },
   "source": [
    "# Transfer Learning CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-n6tVFayGBe"
   },
   "source": [
    "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq8ejXHJyGYq"
   },
   "source": [
    "   ### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWYbxnBayFUP"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c60382438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[1000]))\n",
    "plt.imshow(X_train[66])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (50000, 32, 32, 3)\n",
      "X_test (10000, 32, 32, 3)\n",
      "y_train (50000, 1)\n",
      "y_test (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\",str( X_train.shape))\n",
    "print(\"X_test\",str( X_test.shape))\n",
    "print(\"y_train\",str( y_train.shape))\n",
    "print(\"y_test\",str( y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format(y_train[0])\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Label: {}\".format(y_train[1000]))\n",
    "X_train024 = np.asarray([X_train[key] for (key, label) in enumerate(y_train) if int(label) >= 0 and int(label) <= 4])\n",
    "X_test024 = np.asarray([X_test[key] for (key, label) in enumerate(y_test) if int(label) >= 0 and int(label) <= 4])\n",
    "\n",
    "\n",
    "\n",
    "X_train529 = np.asarray([X_train[key] for (key, label) in enumerate(y_train) if int(label) >= 5 and int(label) <= 9])\n",
    "X_test529 = np.asarray([X_test[key] for (key, label) in enumerate(y_test) if int(label) >= 5 and int(label) <= 9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train024 = X_train024.astype('float32')\n",
    "X_test024 = X_test024.astype('float32')\n",
    "X_train529 = X_train529.astype('float32')\n",
    "X_test529 = X_test529.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train024 = np.asarray([y_train[key] for (key, label) in enumerate(y_train) if int(label) >= 0 and int(label) <= 4])\n",
    "y_test024 = np.asarray([y_test[key] for (key, label) in enumerate(y_test) if int(label) >= 0 and int(label) <= 4])\n",
    "\n",
    "y_train529 = np.asarray([y_train[key] for (key, label) in enumerate(y_train) if int(label) >= 5 and int(label) <= 9])\n",
    "y_test529 = np.asarray([y_test[key] for (key, label) in enumerate(y_test) if int(label) >= 5 and int(label) <= 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtCKmQh4yXhT"
   },
   "source": [
    "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN5O2kJ3yYa6"
   },
   "outputs": [],
   "source": [
    "y_train024 = tf.keras.utils.to_categorical(y_train024, num_classes=5)\n",
    "y_test024 = tf.keras.utils.to_categorical(y_test024, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train529 = y_train529 - 5\n",
    "y_test529 = y_test529 - 5\n",
    "\n",
    "y_train529 = tf.keras.utils.to_categorical(y_train529, num_classes=5)\n",
    "y_test529 = tf.keras.utils.to_categorical(y_test529, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuOiKWfeybAl"
   },
   "source": [
    "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HzxNbiiyoBD"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train024.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 19:51:22.749733 11092 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape = X_train024.shape[1:]\n",
    "model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dense(5,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 10s 418us/step - loss: 1.1502 - acc: 0.5558 - val_loss: 1.6132 - val_acc: 0.4692\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 10s 397us/step - loss: 0.8792 - acc: 0.6542 - val_loss: 0.8657 - val_acc: 0.6676\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 10s 412us/step - loss: 0.7806 - acc: 0.6963 - val_loss: 1.1904 - val_acc: 0.5510\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 10s 401us/step - loss: 0.7188 - acc: 0.7184 - val_loss: 1.0257 - val_acc: 0.6064\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 10s 396us/step - loss: 0.6631 - acc: 0.7426 - val_loss: 0.9305 - val_acc: 0.6420\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 10s 399us/step - loss: 0.6175 - acc: 0.7616 - val_loss: 0.8747 - val_acc: 0.6826\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 10s 402us/step - loss: 0.5834 - acc: 0.7775 - val_loss: 0.7659 - val_acc: 0.7116\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 10s 398us/step - loss: 0.5468 - acc: 0.7904 - val_loss: 0.7600 - val_acc: 0.7212\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 10s 400us/step - loss: 0.5164 - acc: 0.8046 - val_loss: 0.7934 - val_acc: 0.7008\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 10s 401us/step - loss: 0.4869 - acc: 0.8168 - val_loss: 0.7580 - val_acc: 0.7128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c6091dcc0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=X_train024,y=y_train024, epochs=10, validation_data=(X_test024,y_test024),batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woTfNst_ynRG"
   },
   "source": [
    "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_VCDB3Byb1a"
   },
   "outputs": [],
   "source": [
    "# print(model.layers)\n",
    "#Set pre-trained model layers to not trainable\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x0000017C60934128> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000017C60934048> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000017C60934668> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000017C60928BE0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000017C60934748> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000017C60A30B00> False\n",
      "<keras.layers.core.Dropout object at 0x0000017C609E60B8> False\n",
      "<keras.layers.core.Flatten object at 0x0000017C614EDDA0> False\n",
      "<keras.layers.core.Dense object at 0x0000017C61495E10> True\n",
      "<keras.layers.core.Dense object at 0x0000017C61495E48> True\n"
     ]
    }
   ],
   "source": [
    "# Print trainable status of layesrs\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-uUPqWpyeyX"
   },
   "source": [
    "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
    "Achieve an accuracy of more than 85% on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szHjJgDvyfCt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 1.0517 - acc: 0.6269 - val_loss: 0.7560 - val_acc: 0.7120\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 5s 190us/step - loss: 0.6403 - acc: 0.7624 - val_loss: 0.6559 - val_acc: 0.7538\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 5s 190us/step - loss: 0.5493 - acc: 0.7958 - val_loss: 0.6063 - val_acc: 0.7722\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 5s 189us/step - loss: 0.4902 - acc: 0.8216 - val_loss: 0.5679 - val_acc: 0.7862\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 5s 190us/step - loss: 0.4609 - acc: 0.8284 - val_loss: 0.5399 - val_acc: 0.7980\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 5s 189us/step - loss: 0.4237 - acc: 0.8454 - val_loss: 0.5381 - val_acc: 0.7970\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 5s 189us/step - loss: 0.3973 - acc: 0.8555 - val_loss: 0.5253 - val_acc: 0.8066\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 5s 191us/step - loss: 0.3721 - acc: 0.8641 - val_loss: 0.5431 - val_acc: 0.7978\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 5s 191us/step - loss: 0.3498 - acc: 0.8730 - val_loss: 0.5168 - val_acc: 0.8110\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 5s 188us/step - loss: 0.3264 - acc: 0.8830 - val_loss: 0.5030 - val_acc: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d5eee4b00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=X_train529,y=y_train529, epochs=10, validation_data=(X_test529,y_test529),batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zDuRecXzEtr"
   },
   "source": [
    "# Text classification using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMPlEJhHzb6P"
   },
   "source": [
    "### 6. Load the dataset from sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe-B59u3zHNb"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRrMemVQzbHU"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sZX0UbJzmg5"
   },
   "source": [
    "### 7. Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CITr_5aXziJ2"
   },
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: dyer@spdcc.com (Steve Dyer)',\n",
       " 'Subject: Re: Is MSG sensitivity superstition?',\n",
       " 'Organization: S.P. Dyer Computer Consulting, Cambridge MA',\n",
       " 'Lines: 14',\n",
       " '',\n",
       " 'In article <1qnns0$4l3@agate.berkeley.edu> spp@zabriskie.berkeley.edu (Steve Pope) writes:',\n",
       " '>The mass of anectdotal evidence, combined with the lack of',\n",
       " '>a properly constructed scientific experiment disproving',\n",
       " '>the hypothesis, makes the MSG reaction hypothesis the',\n",
       " '>most likely explanation for events.',\n",
       " '',\n",
       " 'You forgot the smiley-face.',\n",
       " '',\n",
       " \"I can't believe this is what they turn out at Berkeley.  Tell me\",\n",
       " \"you're an aberration.\",\n",
       " '',\n",
       " '-- ',\n",
       " 'Steve Dyer',\n",
       " 'dyer@ursa-major.spdcc.com aka {ima,harvard,rayssd,linus,m2c}!spdcc!dyer',\n",
       " '']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[2256].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcESc5QXzr6p"
   },
   "source": [
    "### 8. Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ysInblUMzpvl"
   },
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# twenty_test.target.attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DriL2yZ50DQq"
   },
   "source": [
    "###  a.  You can access the values for the target variable using .target attribute \n",
    "###  b. You can access the name of the class in the target variable with .target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlUuai99z1hX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEKzaDfSz5E-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clBMKHzC0_N1"
   },
   "outputs": [],
   "source": [
    "# twenty_train.data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTz4EaN_1WGc"
   },
   "source": [
    "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5G477f81C0Z"
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer() #min_df=0.01, max_df=0.95)\n",
    "train_data = vec.fit_transform(twenty_train.data)\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tp_fDINJ1t4L"
   },
   "source": [
    "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THlN2b5d1yQp"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = twenty_train.target\n",
    "model=LogisticRegression()\n",
    "log_model = model.fit(train_data,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868175765645806"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vec.transform(twenty_test.data)\n",
    "y_test = twenty_test.target\n",
    "log_model.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R8_External_Lab_Questions_CIFAR10_Transfer_Learning_TFIDF_Text_Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
