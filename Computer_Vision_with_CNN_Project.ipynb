{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import scipy.misc\n",
    "from skimage import transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the images and generate the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertering list of training data paths to df\n",
    "train_dir = './train/'\n",
    "# print(train_dir)\n",
    "train_list = os.listdir(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           image     category\n",
      "0  0050f38b3.png  Black-grass\n",
      "1  0183fdf68.png  Black-grass\n",
      "2  0260cffa8.png  Black-grass\n",
      "3  05eedce4d.png  Black-grass\n",
      "4  075d004bc.png  Black-grass\n"
     ]
    }
   ],
   "source": [
    "# Put train data into dataframe\n",
    "records = []\n",
    "for category in train_list:\n",
    "    img_list = os.listdir(train_dir + category)\n",
    "    for img in img_list:\n",
    "        records.append((img,category))\n",
    "        \n",
    "df_train = pd.DataFrame.from_records(records,columns=['image','category'])\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data 4750\n",
      "Test Data <class 'list'> 794\n",
      "categories ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
      "# of categories 12\n"
     ]
    }
   ],
   "source": [
    "#looking at the test data\n",
    "test_dir = './test'\n",
    "test_list = os.listdir(test_dir)\n",
    "print('Train Data', len(df_train.index))\n",
    "print('Test Data',type(test_list),len(test_list))\n",
    "print('categories',os.listdir(train_dir))\n",
    "print('# of categories', len(os.listdir(train_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1006 18:56:36.871271 16212 image.py:700] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in list(df_train['image'])[0:1]:\n",
    "    img = Image.open(train_dir + df_train['category'][0] + '/' + i)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=\"float32\" )\n",
    "    plt.imshow(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest image dimension 49\n",
      "bad images []\n",
      "Done creating X and y.\n",
      "X Shape (4726, 49, 49, 3)\n"
     ]
    }
   ],
   "source": [
    "dim_image = []\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    data = img.size\n",
    "    dim_image.append(data[0])\n",
    "print('smallest image dimension', min(dim_image))\n",
    "\n",
    "i_height = min(dim_image)\n",
    "i_width = min(dim_image)\n",
    "\n",
    "X = []\n",
    "count = 0\n",
    "bad_images = []\n",
    "#df_train = df_train.drop(df_train.index[bad_images])\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype='float32')\n",
    "    img = img/255\n",
    "    data = transform.resize(img,(49,49))\n",
    "    if data.size != 7203:\n",
    "        bad_images.append(count)\n",
    "#     plt.imshow(data)\n",
    "#     plt.show()\n",
    "#     X.append(data)\n",
    "    count += 1\n",
    "print('bad images',bad_images)\n",
    "\n",
    "df_train = df_train.drop(df_train.index[bad_images])\n",
    "for i in (train_dir + df_train['category'] + '/' + df_train['image']):\n",
    "    img = Image.open(i)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype='float32')\n",
    "    img = img/255\n",
    "    data = transform.resize(img,(49,49))\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "y = np.array(df_train['category'].astype('category').cat.codes)\n",
    "\n",
    "print('Done creating X and y.')\n",
    "print('X Shape',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the data set into Train and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1006 21:43:50.730728 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1006 21:43:50.832153 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1006 21:43:50.866895 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1006 21:43:50.952360 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1006 21:43:51.216421 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1006 21:43:51.232487 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1006 21:43:51.947842 16212 deprecation.py:323] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1006 21:43:52.079811 16212 deprecation_wrapper.py:119] From C:\\Users\\obuli\\.conda\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 946 samples\n",
      "Epoch 1/10\n",
      "3780/3780 [==============================] - 34s 9ms/step - loss: 2.0828 - acc: 0.2704 - val_loss: 1.5633 - val_acc: 0.4863\n",
      "Epoch 2/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 1.2821 - acc: 0.5632 - val_loss: 1.0315 - val_acc: 0.6533\n",
      "Epoch 3/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.9043 - acc: 0.6981 - val_loss: 0.9352 - val_acc: 0.6860\n",
      "Epoch 4/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.7291 - acc: 0.7585 - val_loss: 0.8198 - val_acc: 0.7178\n",
      "Epoch 5/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.5973 - acc: 0.7987 - val_loss: 0.7121 - val_acc: 0.7579\n",
      "Epoch 6/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.4578 - acc: 0.8489 - val_loss: 0.8360 - val_acc: 0.7336\n",
      "Epoch 7/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.3881 - acc: 0.8653 - val_loss: 0.8715 - val_acc: 0.7114\n",
      "Epoch 8/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.3132 - acc: 0.8897 - val_loss: 0.8146 - val_acc: 0.7780\n",
      "Epoch 9/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.2697 - acc: 0.8995 - val_loss: 0.9248 - val_acc: 0.7315\n",
      "Epoch 10/10\n",
      "3780/3780 [==============================] - 7s 2ms/step - loss: 0.2202 - acc: 0.9204 - val_loss: 0.8244 - val_acc: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22461498390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "im_shape = (49,49,3)\n",
    "batch_size = 10\n",
    "\n",
    "cnn  = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), activation='linear', input_shape=im_shape, padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Conv2D(64, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Conv2D(128, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    MaxPooling2D((2,2), padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(12, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "cnn. fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, validation_data=(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
